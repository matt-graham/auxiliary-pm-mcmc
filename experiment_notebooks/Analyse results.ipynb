{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import scipy.io\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load python R interface and import coda for computing chain statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2.interactive as r\n",
    "import rpy2.interactive.packages\n",
    "r.packages.importr(\"coda\")\n",
    "rlib = r.packages.packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for correct printing of values to specified number of significant figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "hide_output": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def to_precision(x, p):\n",
    "    p_str = str(p)\n",
    "    fmt_string = '{0:.' + p_str + 'g}'\n",
    "    return fmt_string.format(x)\n",
    "# alternative method which properly deals with trailing zeros can be got by uncommenting below\n",
    "# to load function by Randle Taylor from git URL\n",
    "# %load https://raw.githubusercontent.com/randlet/to-precision/master/to_precision.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(os.environ['EXP_DIR'], 'apm_mcmc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify file pattern for saved results for different data set and method combination. Ordered dict used so that order is maintained in printed LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name_pattern_map = OrderedDict([\n",
    "    (('Pima', 'PM MH'), '*pima_pmmh_chain_*_results.npz'),\n",
    "    (('Pima', 'APM MI+MH'), '*pima_apm(mi+mh)_chain_*_results.npz'),\n",
    "    (('Pima', 'APM SS+MH'), '*pima_apm(ss+mh)_chain_*_results.npz'),\n",
    "    (('Pima', 'APM SS+SS'), '*pima_apm(ess+rdss)_chain_*_results.npz'),\n",
    "    (('Breast', 'PM MH'), '*breast_pmmh_chain_*_results.npz'),\n",
    "    (('Breast', 'APM MI+MH'), '*breast_apm(mi+mh)_chain_*_results.npz'),\n",
    "    (('Breast', 'APM SS+MH'), '*breast_apm(ss+mh)_chain_*_results.npz'),\n",
    "    (('Breast', 'APM SS+SS'), '*breast_apm(ess+rdss)_chain_*_results.npz'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up saved chains and run stats and store in another ordered dict. Also compute effective sample size and Gelman-Rubin R stat for chains at this point using R-coda interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_map = OrderedDict()\n",
    "for (data_set, method), file_name_pattern in file_name_pattern_map.items():\n",
    "    file_list = glob.glob(os.path.join(exp_dir, file_name_pattern))\n",
    "    chains = []\n",
    "    chains_stats = []\n",
    "    for file_path in file_list:\n",
    "        results = np.load(file_path)\n",
    "        chains.append(results['thetas'])\n",
    "        chains_stats.append(results['n_reject_n_cubic_ops_comp_time'])\n",
    "    chains = np.array(chains)\n",
    "    chains_stats = np.array(chains_stats)\n",
    "    n_effs = np.empty((chains.shape[0], 2))\n",
    "    for i, chain in enumerate(chains):\n",
    "        n_effs[i, 0] = rlib.coda.effectiveSize(chain[:, 0])[0]\n",
    "        n_effs[i, 1] = rlib.coda.effectiveSize(chain[:, 1])[0]\n",
    "    r_chains_list = rlib.coda.as_mcmc_list([rlib.coda.as_mcmc(chain) for chain in chains[:, :, :]])\n",
    "    gelman_rubin = rlib.coda.gelman_diag(r_chains_list, autoburnin=False)\n",
    "    results_map[(data_set, method)] = (chains, chains_stats, n_effs, gelman_rubin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prc_mn = 3 # precision to report means with\n",
    "prc_se = 2 # precision to report standard errors with\n",
    "max_n_chains = 0 # will be populated with max n chains to allow proper \n",
    "                 # formatting of autocorr plots later for cases when\n",
    "                 # plotting intermediate results with differing number\n",
    "                 # of chains completed per method / data set\n",
    "# header for LaTeX table of results\n",
    "latex_table = ''\n",
    "latex_table += ' & Method & $N_\\\\text{cub.cop}$ & Acc. rate '\n",
    "latex_table += '& $N_\\\\text{eff}$ & $\\\\frac{N_\\\\text{eff}}{N_\\\\text{cub.op}}$ & $\\\\hat{R}$ '\n",
    "latex_table += '& $N_\\\\text{eff}$ & $\\\\frac{N_\\\\text{eff}}{N_\\\\text{cub.op}}$ & $\\\\hat{R}$ '\n",
    "latex_table += '\\\\\\\\ \\n \\hline \\n'\n",
    "for (data_set, method), (chains, chains_stats, n_effs, gelman_rubin) in results_map.items():\n",
    "    n_chains, n_samples, n_param = chains.shape\n",
    "    max_n_chains = max(max_n_chains, n_chains) # update record of maximum no. chains\n",
    "    # second column of chain stats is number of cubic operations for a run\n",
    "    # for display purposes, divide by 1000 as easier to visually compare without\n",
    "    # scientific notation\n",
    "    n_kcops = chains_stats[:, 1] / 1000.\n",
    "    # calculate various mean stats over chains and their associated statndard errors\n",
    "    mean_n_k_cub_ops = n_kcops.mean()\n",
    "    ster_n_k_cub_ops = n_kcops.std(ddof=1) / n_chains**0.5\n",
    "    mean_n_eff_samps = n_effs.mean(0)\n",
    "    ster_n_eff_samps = n_effs.std(0, ddof=1) / n_chains**0.5\n",
    "    mean_es_per_kcop = (n_effs / n_kcops[:, None]).mean(0)\n",
    "    ster_es_per_kcop = (n_effs / n_kcops[:, None]).std(0, ddof=1) / n_chains**0.5\n",
    "    acc_rates = 1. - chains_stats[:, 0] * 1. / n_samples\n",
    "    mean_accept_rate = acc_rates.mean()\n",
    "    ster_accept_rate = acc_rates.std(0, ddof=1) / n_chains**0.5\n",
    "    # add row for current results to LaTeX table\n",
    "    latex_table += ' & \\sc {0} & {1} ({2}) & {3} ({4})\\n'.format(\n",
    "        method.lower(), \n",
    "        to_precision(mean_n_k_cub_ops, prc_mn), \n",
    "        to_precision(ster_n_k_cub_ops, prc_se),\n",
    "        to_precision(mean_accept_rate, prc_mn), \n",
    "        to_precision(ster_accept_rate, prc_se)\n",
    "    )\n",
    "    latex_table += ' & {0} ({1}) & {2} ({3}) & {4}\\n'.format(\n",
    "        to_precision(mean_n_eff_samps[0], prc_mn), \n",
    "        to_precision(ster_n_eff_samps[0], prc_se),\n",
    "        to_precision(mean_es_per_kcop[0], prc_mn), \n",
    "        to_precision(ster_es_per_kcop[0], prc_se),\n",
    "        to_precision(gelman_rubin[0][0], prc_mn),\n",
    "    )\n",
    "    latex_table += ' & {0} ({1}) & {2} ({3}) & {4}'.format(\n",
    "        to_precision(mean_n_eff_samps[1], prc_mn), \n",
    "        to_precision(ster_n_eff_samps[1], prc_se),\n",
    "        to_precision(mean_es_per_kcop[1], prc_mn), \n",
    "        to_precision(ster_es_per_kcop[1], prc_se),\n",
    "        to_precision(gelman_rubin[0][1], prc_mn),\n",
    "    )\n",
    "    latex_table += ' \\\\\\\\ \\n'\n",
    "    # Print space delimited table of results for quick checking\n",
    "    print('-' * 55)\n",
    "    print('Data set: {0: <8}  Method: {1: <10}  # chains: {2}'\n",
    "          .format(data_set, method, n_chains))\n",
    "    print('-' * 55)\n",
    "    print('    mean num. k cubic op.            {0: <6} ({1})'\n",
    "          .format(to_precision(mean_n_k_cub_ops, prc_mn), \n",
    "                  to_precision(ster_n_k_cub_ops, prc_se)))\n",
    "    print('    effective sample size  (sigma)   {0: <6} ({1})'\n",
    "          .format(to_precision(mean_n_eff_samps[0], prc_mn), \n",
    "                  to_precision(ster_n_eff_samps[0], prc_se)))\n",
    "    print('    effective sample size  (tau)     {0: <6} ({1})'\n",
    "          .format(to_precision(mean_n_eff_samps[1], prc_mn), \n",
    "                  to_precision(ster_n_eff_samps[1], prc_se)))\n",
    "    print('    eff. samp. / cubic op. (sigma)   {0: <6} ({1})'\n",
    "          .format(to_precision(mean_es_per_kcop[0], prc_mn), \n",
    "                  to_precision(ster_es_per_kcop[0], prc_se)))\n",
    "    print('    eff. samp. / cubic op. (tau)     {0: <6} ({1})'\n",
    "          .format(to_precision(mean_es_per_kcop[1], prc_mn), \n",
    "                  to_precision(ster_es_per_kcop[1], prc_se)))\n",
    "    print('    Gelman-Rubin statistic (sigma)   {0}'\n",
    "          .format(to_precision(gelman_rubin[0][0], prc_mn)))\n",
    "    print('    Gelman-Rubin statistic (tau)     {0}'\n",
    "          .format(to_precision(gelman_rubin[0][1], prc_mn)))\n",
    "    print('    n acc rates off-target           {0}'\n",
    "          .format(np.sum((acc_rates < 0.15) + (acc_rates > 0.30))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print LaTeX table rows for inclusion in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all chains for different method / dataset / variate combinations to a MATLAB readable file to allow loading results there to plot autocorrelations in same style as other figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_chains = 10\n",
    "n_samples = 10000\n",
    "n_methods = len(file_name_pattern_map) / 2\n",
    "pima_sigma_chains = np.empty((n_chains, n_samples, n_methods))\n",
    "pima_tau_chains = np.empty((n_chains, n_samples, n_methods))\n",
    "breast_sigma_chains = np.empty((n_chains, n_samples, n_methods))\n",
    "breast_tau_chains = np.empty((n_chains, n_samples, n_methods))\n",
    "pima_comp_costs = np.empty(n_methods)\n",
    "breast_comp_costs = np.empty(n_methods)\n",
    "pima_method_names = []\n",
    "breast_method_names = []\n",
    "m, n = 0, 0\n",
    "for (data_set, method), (chains, chains_stats, n_effs, gelman_rubin) in results_map.items():\n",
    "    if data_set.lower() == 'pima':\n",
    "        pima_sigma_chains[:, :, m] = chains[:, -n_samples:, 0]\n",
    "        pima_tau_chains[:, :, m] = chains[:, -n_samples:, 1]\n",
    "        pima_method_names.append(method)\n",
    "        pima_comp_costs[m] = chains_stats[:, 1].mean()\n",
    "        m += 1\n",
    "    elif data_set.lower() == 'breast':\n",
    "        breast_sigma_chains[:, :, n] = chains[:, -n_samples:, 0]\n",
    "        breast_tau_chains[:, :, n] = chains[:, -n_samples:, 1]\n",
    "        breast_method_names.append(method)\n",
    "        breast_comp_costs[n] = chains_stats[:, 1].mean()\n",
    "        n += 1\n",
    "pima_rel_comp_costs = pima_comp_costs / pima_comp_costs[0]\n",
    "breast_rel_comp_costs = breast_comp_costs / breast_comp_costs[0]\n",
    "time_stamp = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S_')\n",
    "scipy.io.savemat(os.path.join(exp_dir, time_stamp + 'chains_matlab_dump.mat'),\n",
    "                 {\n",
    "                     'pima_sigma_chains' : pima_sigma_chains,\n",
    "                     'pima_tau_chains' : pima_tau_chains,\n",
    "                     'breast_sigma_chains' : breast_sigma_chains,\n",
    "                     'breast_tau_chains' : breast_tau_chains,\n",
    "                     'pima_rel_comp_costs' : pima_rel_comp_costs,\n",
    "                     'breast_rel_comp_costs' : breast_rel_comp_costs,\n",
    "                     'pima_method_names' : pima_method_names,\n",
    "                     'breast_method_names' : breast_method_names\n",
    "                 }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot autocorrelation plots for all chains - if lots of chains loaded will be a large figure so best viewed externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thin_factor = 10\n",
    "max_lag = 30\n",
    "fig = plt.figure(figsize=(40, 16))\n",
    "n_dm = len(results_map)\n",
    "for i, ((data_set, method), (chains, chains_stats, n_effective, gelman_rubin)) in enumerate(results_map.items()):\n",
    "    for j, chain in enumerate(chains):\n",
    "        ax_tau = fig.add_subplot(max_n_chains, 2 * n_dm, j * 2 * n_dm + 1 + 2 * i % 60)\n",
    "        ax_sig = fig.add_subplot(max_n_chains, 2 * n_dm, j * 2 * n_dm + 2 + 2 * i % 60)\n",
    "        x_tau = chain[::thin_factor, 0].copy()\n",
    "        x_tau -= x_tau.mean()\n",
    "        autocorr_tau = np.correlate(x_tau, x_tau, mode=2)[x_tau.size:]\n",
    "        autocorr_tau /= autocorr_tau[0]\n",
    "        x_sig = chain[::thin_factor, 1].copy()\n",
    "        x_sig -= x_sig.mean()\n",
    "        autocorr_sig = np.correlate(x_sig, x_sig, mode=2)[x_sig.size:]\n",
    "        autocorr_sig /= autocorr_sig[0]\n",
    "        ax_tau.vlines(np.arange(max_lag) + 1, 0., autocorr_tau[:max_lag])\n",
    "        ax_tau.axhline()\n",
    "        ax_tau.set_yticks(np.linspace(-0.4, 0.8, 4))\n",
    "        #ax_tau.set_xticks(np.arange(0, 31, 10))\n",
    "        ax_sig.vlines(np.arange(max_lag) + 1, 0., autocorr_sig[:max_lag])\n",
    "        ax_sig.axhline()\n",
    "        #ax_sig.set_xticks(np.arange(0, 31, 10))\n",
    "        ax_sig.set_yticks(np.linspace(-0.4, 0.8, 4))\n",
    "        if j == 0:\n",
    "            ax_tau.set_title('{0} $\\\\tau$'.format(data_set + ', ' + method))\n",
    "            ax_sig.set_title('{0} $\\\\sigma$'.format(data_set + ', ' + method))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean compute time across 10 chains for PM MH method and APM SS+MH method (for runs on the same machine) to verify that extra quadratic operations for APM approaches here are a negligible overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (data_set, method), (chains, chains_stats, n_effs, gelman_rubin) in results_map.items():\n",
    "    if data_set == 'Pima':\n",
    "        if method == 'PM MH' or method == 'APM SS+MH':\n",
    "            print('{0} {1} mean compute time: {2} +/- {3}'.format(\n",
    "                data_set, method,\n",
    "                to_precision(chains_stats[:, 2].mean(), 3),\n",
    "                to_precision(chains_stats[:, 2].std(ddof=1) / chains.shape[0]**0.5, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
